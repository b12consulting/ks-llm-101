{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool calling\n",
    "\n",
    "In this notebook we explore how to do tool calling in practice.  \n",
    "We will use various libraries to see how they implement tool calling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "Let us start with OpenAI's own library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the model a tool to work with.  \n",
    "Tools can be anything, but since we are working with python, it makes sense to use a python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str):\n",
    "    \"\"\"\n",
    "    Get current temperature for a given location.\n",
    "    \"\"\"\n",
    "    return f\"It temperature is 20 degrees Celsius in {location}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model won't understand what a python function is though,  \n",
    "so we have to present it to the model in a way that it can understand.  \n",
    "Since this is an OpenAI model, we need to follow the OpenAI tool calling format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. Bogot√°, Colombia\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"location\"\n",
    "            ],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BHrPObmqQDFNcKNerfr03t9x9CIYF\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_OvP9hHBg1D4I5npiGMvNtmVE\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"location\\\":\\\"Paris, France\\\"}\",\n",
      "              \"name\": \"get_weather\"\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1743596578,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_b376dfbbd5\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 17,\n",
      "    \"prompt_tokens\": 65,\n",
      "    \"total_tokens\": 82,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "print(completion.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a bit output including some metadata.  \n",
    "Let's look at the message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": null,\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\",\n",
      "  \"annotations\": [],\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"id\": \"call_OvP9hHBg1D4I5npiGMvNtmVE\",\n",
      "      \"function\": {\n",
      "        \"arguments\": \"{\\\"location\\\":\\\"Paris, France\\\"}\",\n",
      "        \"name\": \"get_weather\"\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model expressed that it wants to make a tool call `get_weather(location=\"Paris, France\")`.  \n",
    "Now it is up to use to invoke the python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It temperature is 20 degrees Celsius in Paris, France.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "kwargs_string = completion.choices[0].message.tool_calls[0].function.arguments\n",
    "kwargs = json.loads(kwargs_string)\n",
    "tool_result = get_weather(**kwargs)\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we had to take a couple of steps.  \n",
    "The model outputs a string, which **should** be a valid json string.  \n",
    "We have to parse the json string into a python dictionary.  \n",
    "Then we have the arguments we need to pass to the function.  \n",
    "Finally we can call the function.\n",
    "\n",
    "We can now return the tool result to the model and let it continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"The weather in Paris today is 20 degrees Celsius.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\",\n",
      "  \"annotations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "second_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"},\n",
    "        completion.choices[0].message,\n",
    "        {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": completion.choices[0].message.tool_calls[0].id,\n",
    "        \"content\": tool_result\n",
    "        }\n",
    "    ],\n",
    "    tools=tools,\n",
    ")\n",
    "print(second_completion.choices[0].message.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we allowed the model to make a tool call and it finally responded to the user prompt.\n",
    "\n",
    "That was quite a lot of work though.  \n",
    "This is a common pattern and it makes sense to abstract it away.  \n",
    "\n",
    "Indeed, OpenAI realised this themselves and introduced the Agents SDK.  \n",
    "This recently released API is a convenient wrapper around the tool calling process.  \n",
    "We can now define a tool from a python function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "@function_tool  \n",
    "def get_weather(location: str):\n",
    "    \"\"\"\n",
    "    Get current temperature for a given location.\n",
    "    \"\"\"\n",
    "    return f\"It temperature is 20 degrees Celsius in {location}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents SDK will handle the conversion of the function into the expected format.  \n",
    "Note that the docstring will also be passed to the model,  \n",
    "but the model will see nothing from the body of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: get_weather\n",
      "Description: Get current temperature for a given location.\n",
      "Parameters:\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"location\": {\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"location\"\n",
      "  ],\n",
      "  \"title\": \"get_weather_args\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", get_weather.name)\n",
    "print(\"Description:\", get_weather.description)\n",
    "print(\"Parameters:\")\n",
    "print(json.dumps(get_weather.params_json_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our agent and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The temperature in Paris today is 20 degrees Celsius. If you need more specific weather details, feel free to ask!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "res = await Runner.run(agent, \"What is the weather like in Paris today?\")\n",
    "res.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that was a lot easier!  \n",
    "The Agents SDK took care of:  \n",
    "\n",
    "- the conversion of the python method into the expected format.\n",
    "- The parsing of model response.\n",
    "- The invocation of the tool python method.\n",
    "- Looping on the previous steps until the model is done.\n",
    "\n",
    "Note that the model is \"done\" when it responds with a regular message instead of a tool call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Agents SDK is a nice framework for creating agents, but there are many others.  \n",
    "For example, we have been using LangChain and LangGraph for this purpose for a while.  \n",
    "Let's remind ourselves of how to do the same in LangGraph.  \n",
    "First, we create the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: Annotated[str, \"The location to get the weather for.\"]):\n",
    "    \"\"\"\n",
    "    Get current temperature for a given location.\n",
    "    \"\"\"\n",
    "    return f\"It temperature is 20 degrees Celsius in {location}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly get the schema of the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"Get current temperature for a given location.\",\n",
      "  \"properties\": {\n",
      "    \"location\": {\n",
      "      \"description\": \"The location to get the weather for.\",\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"location\"\n",
      "  ],\n",
      "  \"title\": \"get_weather\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(get_weather.tool_call_schema.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "```\n",
    "def get_weather(location: Annotated[str, \"The location to get the weather for.\"]):\n",
    "```\n",
    "allowed us to annotate the `location` argument with a description.  \n",
    "This will also be passed to the model and can be used to help the model understand what the function does.\n",
    "\n",
    "Now let's create and run the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Assistant\n",
      "\n",
      "The weather in Paris today is 20 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "react_agent = create_react_agent(\n",
    "    name=\"Assistant\",\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "state = react_agent.invoke({\"messages\": [(\"user\", \"What is the weather like in Paris today?\")]})\n",
    "state['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The api is pretty similar to the OpenAI Agents SDK.  \n",
    "But we do not get a vendor lock-in effect, because we can simply switch to another LLM provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Assistant\n",
      "\n",
      "It is 20 degrees Celsius in Paris.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"mistral-small\", base_url=os.getenv(\"OLLAMA_BASE_URL\"))\n",
    "react_agent = create_react_agent(\n",
    "    name=\"Assistant\",\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "state = react_agent.invoke({\"messages\": [(\"user\", \"What is the weather like in Paris today?\")]})\n",
    "state['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
