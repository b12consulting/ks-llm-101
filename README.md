# ks-llm-101

## Knowledge sharing on fundamentals of LLMs

In this repo we go over the basics of working with LLMs.  
Each topic is covered by a notebook:  
- [Chat Templates](./chat_template.ipynb) - What do LLMs actually receive when we send them a prompt? We discuss the concept of chat templates and how to are used to format conversations and tool calls in such the format expected by the LLM.
- [Tool Calling](./tool_calling.ipynb) - How to allow LLMs to make tool calls. This is a crucial ingredient in creating Agentic applications.
- [Structured Output](./structured_output.ipynb) - How to get LLMs to return structured output. This is a crucial ingredient in creating robust LLM applications.

We provide hands-on code examples with both OpenAI, Ollama and LangChain/LangGraph.
